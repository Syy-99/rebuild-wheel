对应章节：

- Chapter 3: Page Tables

## 知识点总结

- 进程的虚拟地址空间管理方式演变：

    1. 利用基址—界限寄存器：将整个程序作为一个整体，并为每个进程分配一个基址寄存器和界限寄存器，基址寄存器存放该虚拟地址在实际物理地址的起点，而界限寄存器则用以判定程序是否访问非法地址

        - 缺点：物理内存被浪费

    2. 分段：将基址加界限的概念泛化，代码、堆和栈段分别维护一个段基址加段界限寄存器，样我们不必要每次都强制的装入整个进程空间

        - 缺点：分段使用的大小是不确定的，容易产生外部碎片

    3. 分页：程序资源划分为固定大小的页，将每一个虚拟页映射到物理页之中，由于每个页是固定大小的，操作系统可以整齐的分配物理内存空间，避免产生了外部碎片

- 分页的三个问题及解决方式：

    1. 怎么记住从虚拟内存页到物理页帧的映射关系？ -> 采用页表

    2. 用户虚拟地址空间庞大，使得页表中的表项数量级大得惊人 -> 采用多级页表

    3. 页表查找时间，使用页表本质上使我们增加了一次或多次访问物理内存的操作，访存时间至少变为原来的2倍（采用多级页表则开销更多） -> 引入TLB

- RISC-V可以处理64位的虚拟地址，而物理地址只被设计成56位; 64位虚拟地址中，只有低39位在被使用，剩下的25位都暂时保留

    ![](https://pic3.zhimg.com/80/v2-b6e8b93e3a459dd7f3b4c044322e5ace_720w.webp)

    - 39位地址空间，其中高27位用来索引PTE, 最多有2^27个PTE

         - 采用三级页表 (2^9 * 2^9 * 2^9 = 2^27)

         - 三次查找有任意一次没有命中，即对应PTE不存在，这种异常的情况称为缺页错误Page-Fault。因为是一个异常，所以进程会陷入内核，由内核来处理缺页错误

         - 一个页表的大小是一个页的大小(4K), 一个页表可以包含512个PTE(4K/8B = 512)
    
    - 每个PTE由44位的物理页帧号PPN和10位的标志位Flags组成. 有效位为54位的PTE可以用8B的大小来存储，这刚好是一个uint64类型

        - PPN +(39-27) = 56(物理地址位数)
    
    - 每个CPU都有自己的****satp寄存器**。CPU在执行指令时，将使用自己的satp寄存器里指向的根页表，完成指令中虚拟地址的转换


- xv6 定义虚拟地址0x8000000以上为内核部分，内核空间的需要注意的有：

    1. trampoline页

        - 一个物理页面（包含trampoline 代码）在虚拟地址空间中被映射了两次：一次在虚拟地址空间顶部，一次是直接映射
     
    2. 内核栈：

        - 每个进程都有自己的内核堆栈，每个内核栈的下面都有一个Guad page来避免溢出

            > - 一个Guard page对应的PTE的Valid 标志位没有设置，这样，如果kernel stack耗尽了，它会溢出到Guard page，但是因为Guard page的PTE中Valid标志位未设置，会导致立即触发page fault，这样的结果好过内存越界之后造成的数据混乱
            > - Guard page不会映射到任何物理内存

        - 内核栈在内核空间中被映射两次,但是在PHYSTOP下的直接映射没有Guad Page

            > 但是实际使用的时候用的是上面的部分，因为有Guard page会更加安全

    >可以向同一个物理地址映射两个虚拟地址

> book中介绍的，所谓的用户空间实际上是用户可用地址空间+内核空间的意思

-  `kernel/main.c`的工作流程，实际上是操作系统初始化的工作：

    1. `kvinit()`: 完成内核的内存分配器的初始化, 获得一块内核可以使用的物理内存页的空闲链表

        - 因为这部分是一一映射，所以可以不需要内核页表

    2. `kvminit()`: 创建内核页表，建立映射

    3. `kvminithart()`: 装载内核页表，将内核根页表的物理地址写入到satp寄存器中，在这之后CPU就会使用内核页表来完成地址转换

    4. `procinit()`: 为每个用户进程在内核空间中分配一个内核栈



## 阅读扩展

Q1: 如何理解内核空间、用户空间?

- 内核空间、用户空间的地址都是虚拟地址，都要经过MMU的翻译变成物理地址

- 从CPU角度看, 所谓内核空间地址/用户空间地址, 只是权限不一样而已,  要获取它们的物理地址, 从硬件层面上, 都要走MMU这套硬件机制， 但是, 软件层面,  可就不一定了：

    1. 当需要知道一个用户空间虚拟地址对应的物理地址，就要通过多级页表来翻译得到它的物理地址
    
    2.  但是, **内核空间虚拟地址是所有进程共享的**(每个进程的虚拟地址空间中的内核空间都一致)，这就有取巧优化的空间了: 内核在初始化时，就创建内核空间的映射（因为所有进程共享，只要维护一个内核空间映射的页表即可)，并且，采用的就是线性映射，
    
        - 所谓线性, 就是内核一整块内核空间页, 一对一地映射到一块物理内存上.  
        
        - 这意味着, 在软件层面(内核),  当内核需要知道它访问的一个内核空间页面Px的物理地址时, 它只要知道第一页P0的物理地址即可, 然后加上Px相距P0的偏移,  即可快速知道Px的物理地址(线性映射的优势), 而不需要走页表翻译这种类似哈希表的方式去计算(当然, 记住,  当内核去访问该页时, 硬件层面仍然走的是MMU翻译的全过程)

Q2: 在创建内核页表进行映射的时候，是否对应的物理内存加载了相应的程序呢(代码/数据)?